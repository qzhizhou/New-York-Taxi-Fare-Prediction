{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # CSV file I/O (e.g. pd.read_csv)\n",
    "import os # reading the input files\n",
    "import matplotlib.pyplot as plt\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16,10))\n",
    "    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n",
    "    axs[0].set_xlim((BB[0], BB[1]))\n",
    "    axs[0].set_ylim((BB[2], BB[3]))\n",
    "    axs[0].set_title('Pickup locations')\n",
    "    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n",
    "\n",
    "    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n",
    "    axs[1].set_xlim((BB[0], BB[1]))\n",
    "    axs[1].set_ylim((BB[2], BB[3]))\n",
    "    axs[1].set_title('Dropoff locations')\n",
    "    axs[1].imshow(nyc_map, zorder=0, extent=BB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_within_boundingbox(df, BB):\n",
    "    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n",
    "           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n",
    "           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n",
    "           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n",
    "    return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n",
    "           (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_datapoints_from_water(df):\n",
    "    def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n",
    "        return (dx * (longitude - BB[0]) / (BB[1] - BB[0])).astype('int'), \\\n",
    "               (dy - dy * (latitude - BB[2]) / (BB[3] - BB[2])).astype('int')\n",
    "\n",
    "    # define bounding box\n",
    "    BB = (-74.5, -72.8, 40.5, 41.8)\n",
    "\n",
    "    # read nyc mask and turn into boolean map with\n",
    "    # land = True, water = False\n",
    "    nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:, :, 0] > 0.9\n",
    "\n",
    "    # calculate for each lon,lat coordinate the xy coordinate in the mask map\n",
    "    pickup_x, pickup_y = lonlat_to_xy(df.pickup_longitude, df.pickup_latitude,\n",
    "                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)\n",
    "    dropoff_x, dropoff_y = lonlat_to_xy(df.dropoff_longitude, df.dropoff_latitude,\n",
    "                                        nyc_mask.shape[1], nyc_mask.shape[0], BB)\n",
    "    # calculate boolean index\n",
    "    idx = nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x]\n",
    "\n",
    "    # return only datapoints on land\n",
    "    return df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_matrix(df):\n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                   object\n",
      "fare_amount          float64\n",
      "pickup_datetime       object\n",
      "pickup_longitude     float64\n",
      "pickup_latitude      float64\n",
      "dropoff_longitude    float64\n",
      "dropoff_latitude     float64\n",
      "passenger_count        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# print(os.listdir('./'))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "train_df =  pd.read_csv('./train.csv', nrows = 10_000_000)\n",
    "print(train_df.dtypes)\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key                    0\n",
      "fare_amount            0\n",
      "pickup_datetime        0\n",
      "pickup_longitude       0\n",
      "pickup_latitude        0\n",
      "dropoff_longitude     69\n",
      "dropoff_latitude      69\n",
      "passenger_count        0\n",
      "abs_diff_longitude    69\n",
      "abs_diff_latitude     69\n",
      "dtype: int64\n",
      "Old size: 10000000\n",
      "New size(without NaN): 9999931\n"
     ]
    }
   ],
   "source": [
    "# remove NaN data\n",
    "print(train_df.isnull().sum())\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df.dropna(how = 'any', axis = 'rows')\n",
    "print('New size(without NaN): %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9999931\n",
      "New size(diff longitude & latitude not to large): 9979187\n"
     ]
    }
   ],
   "source": [
    "# remove unreasonable data which difference of longitude and latitude is too large(which is impossible in NYC)\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size(diff longitude & latitude not to large): %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9979187\n",
      "New size(fare_amount > 0): 9978783\n"
     ]
    }
   ],
   "source": [
    "# remove fare amount < 0\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[train_df.fare_amount>=0]\n",
    "print('New size(fare_amount > 0): %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9787199\n",
      "New size(in NYC): 9787199\n"
     ]
    }
   ],
   "source": [
    "# load image of NYC map\n",
    "BB = (-74.5, -72.8, 40.5, 41.8)\n",
    "nyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')\n",
    "plt.show()\n",
    "\n",
    "# load extra image to zoom in on NYC\n",
    "BB_zoom = (-74.3, -73.7, 40.5, 40.9)\n",
    "nyc_map_zoom = plt.imread('https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png')\n",
    "# remove data not in NYC\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[select_within_boundingbox(train_df, BB)]\n",
    "print('New size(in NYC): %d' % len(train_df))\n",
    "\n",
    "nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trips in water: 2025\n",
      "Old size: 9787199\n",
      "New size(Not in Water): 9785174\n"
     ]
    }
   ],
   "source": [
    "pickup_x, pickup_y = lonlat_to_xy(train_df.pickup_longitude, train_df.pickup_latitude,\n",
    "                                  nyc_mask.shape[1], nyc_mask.shape[0], BB)\n",
    "dropoff_x, dropoff_y = lonlat_to_xy(train_df.dropoff_longitude, train_df.dropoff_latitude,\n",
    "                                  nyc_mask.shape[1], nyc_mask.shape[0], BB)\n",
    "idx = (nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x])\n",
    "print(\"Number of trips in water: {}\".format(np.sum(~idx)))\n",
    "# remove data in watter\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = remove_datapoints_from_water(train_df)\n",
    "print('New size(Not in Water): %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old size: 9785174\n",
      "New size(reasonable passenger count): 9750645\n"
     ]
    }
   ],
   "source": [
    "# remove data with unreasonable passenger numbers\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.passenger_count < 7.0) & (train_df.passenger_count > 0.0)]\n",
    "print('New size(reasonable passenger count): %d' % len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9750645, 3)\n",
      "(9750645,)\n",
      "[167.54495465 118.43263208   4.98442274]\n",
      "[167.54495465 118.43263208   4.98442274]\n",
      "ww\n"
     ]
    }
   ],
   "source": [
    "#save the trained data \n",
    "train_df.to_csv('Train_Processed.csv')\n",
    "\n",
    "train_X = get_input_matrix(train_df)\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "# call lstsq to train input data\n",
    "(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond = None)\n",
    "print(w)\n",
    "w_OLS = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_X.T, train_X)), train_X.T), train_y)\n",
    "print(w_OLS)\n",
    "print('ww')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00811005 0.01996994 1.        ]\n",
      " [0.01202393 0.01981735 1.        ]\n",
      " [0.00287    0.005121   1.        ]\n",
      " ...\n",
      " [0.20185852 0.07959747 1.        ]\n",
      " [0.04639435 0.06629944 1.        ]\n",
      " [0.01226044 0.00514984 1.        ]]\n",
      "['XgboostWithZhibinData.pdf', '1_alldata_allfeatures.pkl', 'Untitled1.ipynb', 'add_features.ipynb', 'preprocess_and_linear_model.py', '.DS_Store', 'process_test.py', 'Untitled.ipynb', 'record.txt', 'Record.docx', 'XgboostWithZhibinData.ipynb', 'test.csv', 'submission.csv', 'Preprocess_data_4.23.py', 'pre.txt', 'Train_Processed_4.23.csv.zip', '__pycache__', 'test.py', 'new-york-city-taxi-fare-prediction', 'GCP-Coupons-Instructions.rtf', 'test_new_feature.csv', 'test_copy.csv', 'pickle_model.pkl', 'Train_Processed_4.23.csv', 'train.csv', 'test_new_feature.csv.zip', '.ipynb_checkpoints', 'venv', 'Zhibin_xgboost.py', '1_alldata_allfeatures.csv', 'sample_submission.csv', 'nyc-taxi-fare-data-exploration.ipynb', '.idea']\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('./test_copy.csv')\n",
    "# Reuse the above helper functions to add our features and generate the input matrix.\n",
    "add_travel_vector_features(test_df)\n",
    "test_X = get_input_matrix(test_df)\n",
    "print(test_X)\n",
    "# Predict fare_amount on the test set using our model (w) trained on the training set.\n",
    "test_y_predictions = np.matmul(test_X, w).round(decimals = 2)\n",
    "\n",
    "# Write the predictions to a CSV file which we can submit to the competition.\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_y_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
